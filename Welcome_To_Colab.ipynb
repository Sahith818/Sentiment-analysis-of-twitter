{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# -------------------------------\n",
        "# Create models folder\n",
        "# -------------------------------\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "# ==========================================================\n",
        "# 1️⃣ SENTIMENT ANALYSIS ON TWITTER DATA\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n========== Sentiment Analysis on Twitter Data ==========\\n\")\n",
        "\n",
        "# Create synthetic Twitter-like dataset (you can replace this with real tweets later)\n",
        "np.random.seed(42)\n",
        "\n",
        "positive_templates = [\n",
        "    \"I love {}\", \"So happy with {}\", \"{} made my day.\", \"Fantastic experience with {}\",\n",
        "    \"Absolutely recommend {}\", \"Feeling great about {}\"\n",
        "]\n",
        "negative_templates = [\n",
        "    \"I hate {}\", \"Terrible experience with {}\", \"{} ruined my day.\", \"Very disappointed with {}\",\n",
        "    \"Never using {} again.\", \"So upset about {}\"\n",
        "]\n",
        "neutral_templates = [\n",
        "    \"{} is okay.\", \"It's about {}\", \"I have no opinion about {}\", \"{} was average.\",\n",
        "    \"Neither good nor bad about {}\"\n",
        "]\n",
        "entities = [\"the new update\", \"this app\", \"customer service\", \"the product\", \"their support\", \"the event\"]\n",
        "\n",
        "def make_tweet(label):\n",
        "    if label == \"positive\":\n",
        "        return np.random.choice(positive_templates).format(np.random.choice(entities))\n",
        "    elif label == \"negative\":\n",
        "        return np.random.choice(negative_templates).format(np.random.choice(entities))\n",
        "    else:\n",
        "        return np.random.choice(neutral_templates).format(np.random.choice(entities))\n",
        "\n",
        "n = 600\n",
        "labels = np.random.choice([\"positive\", \"negative\", \"neutral\"], size=n, p=[0.4, 0.35, 0.25])\n",
        "tweets = [make_tweet(l) for l in labels]\n",
        "\n",
        "sent_df = pd.DataFrame({\"text\": tweets, \"label\": labels})\n",
        "print(\"Sample Sentiment Data:\\n\", sent_df.head(), \"\\n\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sent_df[\"text\"], sent_df[\"label\"], test_size=0.2, random_state=42, stratify=sent_df[\"label\"]\n",
        ")\n",
        "\n",
        "# Build pipeline (TF-IDF + Logistic Regression)\n",
        "sent_pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), max_features=5000)),\n",
        "    (\"clf\", LogisticRegression(max_iter=1000, solver='lbfgs'))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "sent_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = sent_pipeline.predict(X_test)\n",
        "print(\"=== Classification Report (Sentiment Analysis) ===\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Save model\n",
        "joblib.dump(sent_pipeline, \"models/sentiment_pipeline.joblib\")\n",
        "print(\"\\n✅ Sentiment model saved as: models/sentiment_pipeline.joblib\\n\")\n",
        "\n",
        "# ==========================================================\n",
        "# 2️⃣ CUSTOMER CHURN PREDICTION\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n========== Customer Churn Prediction ==========\\n\")\n",
        "\n",
        "# Create synthetic dataset for churn prediction\n",
        "X_num, y = make_classification(\n",
        "    n_samples=2000, n_features=10, n_informative=6, n_redundant=2,\n",
        "    n_clusters_per_class=2, weights=[0.7,0.3], flip_y=0.03, random_state=42\n",
        ")\n",
        "\n",
        "num_cols = [f\"num_{i}\" for i in range(X_num.shape[1])]\n",
        "churn_df = pd.DataFrame(X_num, columns=num_cols)\n",
        "\n",
        "# Add synthetic categorical columns\n",
        "churn_df[\"Contract\"] = pd.cut(churn_df[\"num_0\"], bins=3, labels=[\"Month-to-month\", \"One year\", \"Two year\"])\n",
        "churn_df[\"PaymentMethod\"] = np.where(churn_df[\"num_1\"] > 0, \"Electronic check\", \"Mailed check\")\n",
        "churn_df[\"SeniorCitizen\"] = (churn_df[\"num_2\"] > 0.5).astype(int)\n",
        "churn_df[\"tenure_months\"] = (np.abs(churn_df[\"num_3\"]) * 12).astype(int).clip(0, 72)\n",
        "churn_df[\"Churn\"] = np.where(y == 1, \"Yes\", \"No\")\n",
        "\n",
        "print(\"Sample Churn Data:\\n\", churn_df.head(), \"\\n\")\n",
        "\n",
        "# Define target and features\n",
        "target = \"Churn\"\n",
        "categorical_features = [\"Contract\", \"PaymentMethod\", \"SeniorCitizen\"]\n",
        "numerical_features = [c for c in churn_df.columns if c.startswith(\"num_\")] + [\"tenure_months\"]\n",
        "\n",
        "X = churn_df[categorical_features + numerical_features]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-fE9_EukpcJ",
        "outputId": "00a2114c-fad9-41b9-ebdd-c1ed447e8f54"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== Sentiment Analysis on Twitter Data ==========\n",
            "\n",
            "Sample Sentiment Data:\n",
            "                             text     label\n",
            "0  Absolutely recommend this app  positive\n",
            "1          this app was average.   neutral\n",
            "2   Never using the event again.  negative\n",
            "3   Never using the event again.  negative\n",
            "4           I love their support  positive \n",
            "\n",
            "=== Classification Report (Sentiment Analysis) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00        39\n",
            "     neutral       1.00      1.00      1.00        32\n",
            "    positive       1.00      1.00      1.00        49\n",
            "\n",
            "    accuracy                           1.00       120\n",
            "   macro avg       1.00      1.00      1.00       120\n",
            "weighted avg       1.00      1.00      1.00       120\n",
            "\n",
            "Confusion Matrix:\n",
            " [[39  0  0]\n",
            " [ 0 32  0]\n",
            " [ 0  0 49]]\n",
            "\n",
            "✅ Sentiment model saved as: models/sentiment_pipeline.joblib\n",
            "\n",
            "\n",
            "========== Customer Churn Prediction ==========\n",
            "\n",
            "Sample Churn Data:\n",
            "       num_0     num_1     num_2     num_3     num_4     num_5     num_6  \\\n",
            "0 -0.913297 -0.048776 -1.263867 -1.919355 -1.208197  2.516587  1.538686   \n",
            "1 -0.334132 -0.228151 -2.994822 -1.420724 -1.887356 -0.210312  0.975160   \n",
            "2 -0.988407  1.634863  1.915971 -0.149744  1.752287  1.407583 -0.631496   \n",
            "3  0.003170  0.115240 -1.797795 -0.371989 -2.325619  1.193047  0.711432   \n",
            "4  2.551424 -0.485110 -2.255119 -1.415234 -0.696591 -3.483726  0.650426   \n",
            "\n",
            "      num_7     num_8     num_9  Contract     PaymentMethod  SeniorCitizen  \\\n",
            "0  0.100100  4.730559  1.559182  One year      Mailed check              0   \n",
            "1  1.898796  0.665476  0.360016  One year      Mailed check              0   \n",
            "2 -2.464059  0.802058 -1.207775  One year  Electronic check              1   \n",
            "3  2.077680  1.339276 -0.243406  One year  Electronic check              0   \n",
            "4 -1.637152  0.777939 -1.400670  Two year      Mailed check              0   \n",
            "\n",
            "   tenure_months Churn  \n",
            "0             23    No  \n",
            "1             17    No  \n",
            "2              1   Yes  \n",
            "3              4    No  \n",
            "4             16    No   \n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}